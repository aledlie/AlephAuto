This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
test-files/
  test1.md
  test2.md
  test3.md
directory-scanner.test.js
README_ENHANCED.md
readme-scanner.test.js
repomix-worker.test.js
schema-mcp-tools.test.js
sidequest-server.test.js
test-directory-scanner.js
test-sentry-connection.js
test-single-enhancement.js
test-single-job.js
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="test-files/test1.md">
# Test Document 1

This is a test markdown file.

## Section 1

Some content here.

## Section 2

More test content.
</file>

<file path="test-files/test2.md">
# Test Document 2

Another test markdown file.

## Features

- Item 1
- Item 2
- Item 3

## Code Example

```javascript
console.log('Hello, world!');
```
</file>

<file path="test-files/test3.md">
# Test Document 3

Third test file with different content.

## Table Example

| Column 1 | Column 2 | Column 3 |
|----------|----------|----------|
| Data 1   | Data 2   | Data 3   |
| Data 4   | Data 5   | Data 6   |

## Links

[Example Link](https://example.com)
</file>

<file path="directory-scanner.test.js">
import { test, describe } from 'node:test';
import assert from 'node:assert';
import { DirectoryScanner } from '../sidequest/directory-scanner.js';
import fs from 'fs/promises';
import path from 'path';
import os from 'os';

describe('DirectoryScanner', () => {
  test('should initialize with default options', () => {
    const scanner = new DirectoryScanner();
    assert.strictEqual(scanner.baseDir, path.join(os.homedir(), 'code'));
    assert.strictEqual(scanner.outputDir, './directory-scan-reports');
    assert.ok(scanner.excludeDirs.has('node_modules'));
    assert.ok(scanner.excludeDirs.has('.git'));
    assert.strictEqual(scanner.maxDepth, 10);
  });

  test('should initialize with custom options', () => {
    const customDir = '/custom/path';
    const customOutputDir = '/custom/output';
    const customExclude = ['custom1', 'custom2'];
    const scanner = new DirectoryScanner({
      baseDir: customDir,
      outputDir: customOutputDir,
      excludeDirs: customExclude,
      maxDepth: 5,
    });

    assert.strictEqual(scanner.baseDir, customDir);
    assert.strictEqual(scanner.outputDir, customOutputDir);
    assert.ok(scanner.excludeDirs.has('custom1'));
    assert.strictEqual(scanner.maxDepth, 5);
  });

  test('should create excludeDirs as a Set', () => {
    const scanner = new DirectoryScanner({
      excludeDirs: ['node_modules', 'dist'],
    });

    assert.ok(scanner.excludeDirs instanceof Set);
    assert.strictEqual(scanner.excludeDirs.size, 2);
  });

  test('should scan directories in test fixture', async () => {
    // Create a temporary test directory structure
    const tempDir = path.join(os.tmpdir(), 'test-scanner-' + Date.now());

    try {
      await fs.mkdir(tempDir, { recursive: true });
      await fs.mkdir(path.join(tempDir, 'project1'));
      await fs.mkdir(path.join(tempDir, 'project2'));
      await fs.mkdir(path.join(tempDir, 'node_modules')); // Should be excluded
      await fs.mkdir(path.join(tempDir, 'project1', 'src'));

      const scanner = new DirectoryScanner({
        baseDir: tempDir,
        excludeDirs: ['node_modules'],
      });

      const directories = await scanner.scanDirectories();

      // Should find project1, project2, and project1/src (not node_modules)
      assert.ok(directories.length >= 3);
      const names = directories.map(d => d.name);
      assert.ok(names.includes('project1'));
      assert.ok(names.includes('project2'));
      assert.ok(names.includes('src'));
      assert.ok(!names.includes('node_modules'));
    } finally {
      // Cleanup
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('should respect maxDepth limit', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-depth-' + Date.now());

    try {
      // Create deep directory structure
      await fs.mkdir(tempDir, { recursive: true });
      await fs.mkdir(path.join(tempDir, 'level1'));
      await fs.mkdir(path.join(tempDir, 'level1', 'level2'));
      await fs.mkdir(path.join(tempDir, 'level1', 'level2', 'level3'));

      const scanner = new DirectoryScanner({
        baseDir: tempDir,
        maxDepth: 1,
      });

      const directories = await scanner.scanDirectories();

      // Should only find level1, not level2 or level3
      const depths = directories.map(d => d.depth);
      assert.ok(Math.max(...depths) <= 1);
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('should handle permission errors gracefully', async () => {
    const scanner = new DirectoryScanner({
      baseDir: '/nonexistent/path/that/does/not/exist',
    });

    // Should not throw, just return empty array
    const directories = await scanner.scanDirectories();
    assert.strictEqual(directories.length, 0);
  });

  test('shouldProcess should return true for valid directories', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-process-' + Date.now());

    try {
      await fs.mkdir(tempDir, { recursive: true });
      await fs.writeFile(path.join(tempDir, 'file.txt'), 'content');

      const scanner = new DirectoryScanner();
      const result = await scanner.shouldProcess(tempDir);

      assert.strictEqual(result, true);
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('shouldProcess should return false for non-directories', async () => {
    const tempFile = path.join(os.tmpdir(), 'test-file-' + Date.now() + '.txt');

    try {
      await fs.writeFile(tempFile, 'content');

      const scanner = new DirectoryScanner();
      const result = await scanner.shouldProcess(tempFile);

      assert.strictEqual(result, false);
    } finally {
      await fs.rm(tempFile, { force: true });
    }
  });

  test('should generate scan statistics', () => {
    const scanner = new DirectoryScanner();
    const directories = [
      { name: 'project1', depth: 0, relativePath: 'project1', fullPath: '/test/project1' },
      { name: 'project2', depth: 0, relativePath: 'project2', fullPath: '/test/project2' },
      { name: 'src', depth: 1, relativePath: 'project1/src', fullPath: '/test/project1/src' },
      { name: 'src', depth: 1, relativePath: 'project2/src', fullPath: '/test/project2/src' },
      { name: 'lib', depth: 1, relativePath: 'project1/lib', fullPath: '/test/project1/lib' },
    ];

    const stats = scanner.generateScanStats(directories);

    assert.strictEqual(stats.total, 5);
    assert.strictEqual(stats.byDepth[0], 2);
    assert.strictEqual(stats.byDepth[1], 3);
    assert.strictEqual(stats.byName['src'], 2);
    assert.strictEqual(stats.byName['project1'], 1);
    assert.ok(stats.topDirectoryNames.length > 0);
  });

  test('should generate directory tree', () => {
    const scanner = new DirectoryScanner({ baseDir: '/test/base' });
    const directories = [
      { name: 'project1', depth: 0, relativePath: 'project1', fullPath: '/test/base/project1' },
      { name: 'src', depth: 1, relativePath: 'project1/src', fullPath: '/test/base/project1/src' },
    ];

    const tree = scanner.generateDirectoryTree(directories);

    assert.ok(tree.includes('Directory Tree:'));
    assert.ok(tree.includes('/test/base'));
    assert.ok(tree.includes('project1/'));
    assert.ok(tree.includes('src/'));
  });

  test('should save scan report', async () => {
    const tempOutputDir = path.join(os.tmpdir(), 'test-output-' + Date.now());

    try {
      const scanner = new DirectoryScanner({
        baseDir: '/test',
        outputDir: tempOutputDir,
      });

      const directories = [
        { name: 'project1', depth: 0, relativePath: 'project1', fullPath: '/test/project1' },
      ];

      const stats = scanner.generateScanStats(directories);
      const reportPath = await scanner.saveScanReport(directories, stats);

      // Check that report file was created
      const reportExists = await fs.access(reportPath).then(() => true).catch(() => false);
      assert.ok(reportExists);

      // Check report content
      const reportContent = await fs.readFile(reportPath, 'utf-8');
      const report = JSON.parse(reportContent);

      assert.ok(report.timestamp);
      assert.strictEqual(report.baseDir, '/test');
      assert.strictEqual(report.scanStats.total, 1);
      assert.strictEqual(report.directories.length, 1);
    } finally {
      await fs.rm(tempOutputDir, { recursive: true, force: true });
    }
  });

  test('should save directory tree', async () => {
    const tempOutputDir = path.join(os.tmpdir(), 'test-tree-' + Date.now());

    try {
      const scanner = new DirectoryScanner({
        baseDir: '/test',
        outputDir: tempOutputDir,
      });

      const directories = [
        { name: 'project1', depth: 0, relativePath: 'project1', fullPath: '/test/project1' },
      ];

      const treePath = await scanner.saveDirectoryTree(directories);

      // Check that tree file was created
      const treeExists = await fs.access(treePath).then(() => true).catch(() => false);
      assert.ok(treeExists);

      // Check tree content
      const treeContent = await fs.readFile(treePath, 'utf-8');
      assert.ok(treeContent.includes('Directory Tree:'));
      assert.ok(treeContent.includes('/test'));
    } finally {
      await fs.rm(tempOutputDir, { recursive: true, force: true });
    }
  });

  test('should generate and save complete scan results', async () => {
    const tempOutputDir = path.join(os.tmpdir(), 'test-complete-' + Date.now());

    try {
      const scanner = new DirectoryScanner({
        baseDir: '/test',
        outputDir: tempOutputDir,
      });

      const directories = [
        { name: 'project1', depth: 0, relativePath: 'project1', fullPath: '/test/project1' },
        { name: 'src', depth: 1, relativePath: 'project1/src', fullPath: '/test/project1/src' },
      ];

      const results = await scanner.generateAndSaveScanResults(directories);

      // Check all output files
      assert.ok(results.summary);
      assert.ok(results.reportPath);
      assert.ok(results.treePath);
      assert.ok(results.summaryPath);

      // Verify summary content
      assert.strictEqual(results.summary.totalDirectories, 2);
      assert.strictEqual(results.summary.maxDepth, 1);
      assert.strictEqual(results.summary.baseDir, '/test');

      // Verify all files exist
      const reportExists = await fs.access(results.reportPath).then(() => true).catch(() => false);
      const treeExists = await fs.access(results.treePath).then(() => true).catch(() => false);
      const summaryExists = await fs.access(results.summaryPath).then(() => true).catch(() => false);

      assert.ok(reportExists);
      assert.ok(treeExists);
      assert.ok(summaryExists);

      // Verify summary file content
      const summaryContent = await fs.readFile(results.summaryPath, 'utf-8');
      const summary = JSON.parse(summaryContent);

      assert.strictEqual(summary.totalDirectories, 2);
      assert.ok(summary.stats.topDirectoryNames);
    } finally {
      await fs.rm(tempOutputDir, { recursive: true, force: true });
    }
  });
});
</file>

<file path="README_ENHANCED.md">
# test

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "test",
  "description": "Directory containing 4 code files with 0 classes and 4 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "4 function definitions"
  ]
}
</script>

## Overview

This directory contains 4 code file(s) with extracted schemas.

## Subdirectories

- `test-files/`

## Files and Schemas

### `test-directory-scanner.js` (typescript)

**Functions:**
- `async testDirectoryScanner()` - Line 8

### `test-sentry-connection.js` (typescript)

**Functions:**
- `async testSentryConnection()` - Line 12

### `test-single-enhancement.js` (typescript)

**Functions:**
- `async testSingleEnhancement()` - Line 9

### `test-single-job.js` (typescript)

**Functions:**
- `async testSingleJob()` - Line 10

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="readme-scanner.test.js">
import { test, describe } from 'node:test';
import assert from 'node:assert';
import { READMEScanner } from '../sidequest/doc-enhancement/readme-scanner.js';
import fs from 'fs/promises';
import path from 'path';
import os from 'os';

describe('READMEScanner', () => {
  test('should initialize with default options', () => {
    const scanner = new READMEScanner();
    assert.strictEqual(scanner.baseDir, process.cwd());
    assert.ok(scanner.excludeDirs.has('node_modules'));
    assert.ok(scanner.excludeDirs.has('.git'));
    assert.strictEqual(scanner.maxDepth, 10);
    assert.ok(Array.isArray(scanner.readmePatterns));
  });

  test('should initialize with custom options', () => {
    const customDir = '/custom/path';
    const scanner = new READMEScanner({
      baseDir: customDir,
      maxDepth: 5,
      readmePatterns: ['README.md'],
    });

    assert.strictEqual(scanner.baseDir, customDir);
    assert.strictEqual(scanner.maxDepth, 5);
    assert.strictEqual(scanner.readmePatterns.length, 1);
  });

  test('should identify README files correctly', () => {
    const scanner = new READMEScanner();

    assert.strictEqual(scanner.isREADMEFile('README.md'), true);
    assert.strictEqual(scanner.isREADMEFile('readme.md'), true);
    assert.strictEqual(scanner.isREADMEFile('Readme.md'), true);
    assert.strictEqual(scanner.isREADMEFile('index.js'), false);
    assert.strictEqual(scanner.isREADMEFile('package.json'), false);
  });

  test('should scan for README files', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-readme-scan-' + Date.now());

    try {
      // Create test directory structure with READMEs
      await fs.mkdir(path.join(tempDir, 'project1'), { recursive: true });
      await fs.mkdir(path.join(tempDir, 'project2'), { recursive: true });
      await fs.writeFile(path.join(tempDir, 'README.md'), '# Root');
      await fs.writeFile(path.join(tempDir, 'project1', 'README.md'), '# Project 1');
      await fs.writeFile(path.join(tempDir, 'project2', 'readme.md'), '# Project 2');
      await fs.writeFile(path.join(tempDir, 'project1', 'index.js'), 'console.log("test")');

      const scanner = new READMEScanner({
        baseDir: tempDir,
        excludeDirs: ['node_modules'],
      });

      const readmes = await scanner.scanREADMEs();

      // Should find 3 README files
      assert.strictEqual(readmes.length, 3);
      const fileNames = readmes.map(r => r.fileName);
      assert.ok(fileNames.includes('README.md'));
      assert.ok(fileNames.includes('readme.md'));
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('should detect schema markup in README', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-schema-detect-' + Date.now());

    try {
      await fs.mkdir(tempDir, { recursive: true });

      // README without schema
      const readmeWithout = path.join(tempDir, 'README-without.md');
      await fs.writeFile(readmeWithout, '# Test\n\nThis is a test.');

      // README with schema
      const readmeWith = path.join(tempDir, 'README-with.md');
      await fs.writeFile(readmeWith, '# Test\n\n<script type="application/ld+json">\n{}\n</script>');

      const scanner = new READMEScanner();

      const hasSchemaWithout = await scanner.hasSchemaMarkup(readmeWithout);
      const hasSchemaWith = await scanner.hasSchemaMarkup(readmeWith);

      assert.strictEqual(hasSchemaWithout, false);
      assert.strictEqual(hasSchemaWith, true);
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('should read README content', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-readme-read-' + Date.now());

    try {
      await fs.mkdir(tempDir, { recursive: true });
      const readmePath = path.join(tempDir, 'README.md');
      const content = '# Test README\n\nThis is a test.';
      await fs.writeFile(readmePath, content);

      const scanner = new READMEScanner();
      const readContent = await scanner.readREADME(readmePath);

      assert.strictEqual(readContent, content);
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('should gather context from directory', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-context-' + Date.now());

    try {
      await fs.mkdir(tempDir, { recursive: true });

      // Create files to detect languages
      await fs.writeFile(path.join(tempDir, 'index.js'), 'console.log("test")');
      await fs.writeFile(path.join(tempDir, 'main.py'), 'print("test")');
      await fs.writeFile(path.join(tempDir, 'package.json'), '{}');

      const scanner = new READMEScanner();
      const context = await scanner.gatherContext(tempDir);

      assert.ok(context.languages.has('JavaScript'));
      assert.ok(context.languages.has('Python'));
      assert.strictEqual(context.hasPackageJson, true);
      assert.strictEqual(context.projectType, 'nodejs');
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('should detect multiple languages', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-multi-lang-' + Date.now());

    try {
      await fs.mkdir(tempDir, { recursive: true });

      // Create files in different languages
      await fs.writeFile(path.join(tempDir, 'index.ts'), 'const x: string = "test"');
      await fs.writeFile(path.join(tempDir, 'main.go'), 'package main');
      await fs.writeFile(path.join(tempDir, 'app.rs'), 'fn main() {}');

      const scanner = new READMEScanner();
      const context = await scanner.gatherContext(tempDir);

      assert.ok(context.languages.has('TypeScript'));
      assert.ok(context.languages.has('Go'));
      assert.ok(context.languages.has('Rust'));
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('should get stats about scanned READMEs', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-readme-stats-' + Date.now());

    try {
      await fs.mkdir(tempDir, { recursive: true });
      await fs.writeFile(path.join(tempDir, 'README.md'), '# Test');
      await fs.writeFile(path.join(tempDir, 'README-with.md'), '# Test\n<script type="application/ld+json">\n{}\n</script>');

      const scanner = new READMEScanner({
        baseDir: tempDir,
        readmePatterns: ['README.md', 'README-with.md']
      });
      const readmes = await scanner.scanREADMEs();
      const stats = await scanner.getStats(readmes);

      assert.strictEqual(stats.total, 2);
      assert.strictEqual(stats.withSchema, 1);
      assert.strictEqual(stats.withoutSchema, 1);
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('should respect maxDepth limit', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-readme-depth-' + Date.now());

    try {
      // Create deep directory structure with READMEs
      await fs.mkdir(path.join(tempDir, 'level1', 'level2', 'level3'), { recursive: true });
      await fs.writeFile(path.join(tempDir, 'README.md'), '# Root');
      await fs.writeFile(path.join(tempDir, 'level1', 'README.md'), '# Level 1');
      await fs.writeFile(path.join(tempDir, 'level1', 'level2', 'README.md'), '# Level 2');
      await fs.writeFile(path.join(tempDir, 'level1', 'level2', 'level3', 'README.md'), '# Level 3');

      const scanner = new READMEScanner({
        baseDir: tempDir,
        maxDepth: 2,
      });

      const readmes = await scanner.scanREADMEs();

      // Should only find READMEs up to depth 2
      const depths = readmes.map(r => r.depth);
      assert.ok(Math.max(...depths) <= 2);
      assert.ok(readmes.length <= 3); // Root, level1, level2
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });

  test('should exclude specified directories', async () => {
    const tempDir = path.join(os.tmpdir(), 'test-readme-exclude-' + Date.now());

    try {
      await fs.mkdir(path.join(tempDir, 'src'), { recursive: true });
      await fs.mkdir(path.join(tempDir, 'node_modules'), { recursive: true });
      await fs.writeFile(path.join(tempDir, 'src', 'README.md'), '# Src');
      await fs.writeFile(path.join(tempDir, 'node_modules', 'README.md'), '# Node Modules');

      const scanner = new READMEScanner({
        baseDir: tempDir,
        excludeDirs: ['node_modules'],
      });

      const readmes = await scanner.scanREADMEs();

      // Should only find README in src, not in node_modules
      assert.strictEqual(readmes.length, 1);
      assert.ok(readmes[0].relativePath.includes('src'));
    } finally {
      await fs.rm(tempDir, { recursive: true, force: true });
    }
  });
});
</file>

<file path="repomix-worker.test.js">
import { test, describe } from 'node:test';
import assert from 'node:assert';
import { RepomixWorker } from '../sidequest/repomix-worker.js';
import fs from 'fs/promises';
import path from 'path';
import os from 'os';

describe('RepomixWorker', () => {
  test('should initialize with default options', () => {
    const worker = new RepomixWorker();
    assert.strictEqual(worker.outputBaseDir, './condense');
    assert.strictEqual(worker.codeBaseDir, path.join(os.homedir(), 'code'));
  });

  test('should initialize with custom options', () => {
    const worker = new RepomixWorker({
      outputBaseDir: '/custom/output',
      codeBaseDir: '/custom/code',
      maxConcurrent: 3,
    });

    assert.strictEqual(worker.outputBaseDir, '/custom/output');
    assert.strictEqual(worker.codeBaseDir, '/custom/code');
    assert.strictEqual(worker.maxConcurrent, 3);
  });

  test('should create a repomix job with correct structure', () => {
    const worker = new RepomixWorker();
    const sourceDir = '/test/source/dir';
    const relativePath = 'project/subdir';

    const job = worker.createRepomixJob(sourceDir, relativePath);

    assert.ok(job.id.includes('repomix-'));
    assert.ok(job.id.includes('project-subdir'));
    assert.strictEqual(job.data.sourceDir, sourceDir);
    assert.strictEqual(job.data.relativePath, relativePath);
    assert.strictEqual(job.data.type, 'repomix');
  });

  test('should generate unique job IDs', () => {
    const worker = new RepomixWorker();
    const job1 = worker.createRepomixJob('/test/dir1', 'dir1');
    const job2 = worker.createRepomixJob('/test/dir2', 'dir2');

    assert.notStrictEqual(job1.id, job2.id);
  });

  test('should create output directory structure', async () => {
    const tempOutputDir = path.join(os.tmpdir(), 'test-output-' + Date.now());
    const tempSourceDir = path.join(os.tmpdir(), 'test-source-' + Date.now());

    try {
      // Create a test source directory with some files
      await fs.mkdir(tempSourceDir, { recursive: true });
      await fs.writeFile(path.join(tempSourceDir, 'test.txt'), 'test content');

      const worker = new RepomixWorker({
        outputBaseDir: tempOutputDir,
        logDir: path.join(tempOutputDir, 'logs'),
      });

      // Create logs directory
      await fs.mkdir(path.join(tempOutputDir, 'logs'), { recursive: true });

      const relativePath = 'test/project';

      // Create job - it will fail because repomix might not be installed or work
      // but we can still verify the directory structure is created
      const job = worker.createRepomixJob(tempSourceDir, relativePath);

      // Wait a bit for job to attempt execution
      await new Promise((resolve) => setTimeout(resolve, 1000));

      // Check that output directory was created
      const outputDir = path.join(tempOutputDir, relativePath);
      const dirExists = await fs.access(outputDir).then(() => true).catch(() => false);

      // Directory should exist even if repomix fails
      assert.ok(dirExists, 'Output directory should be created');
    } finally {
      await fs.rm(tempOutputDir, { recursive: true, force: true });
      await fs.rm(tempSourceDir, { recursive: true, force: true });
    }
  });

  test('should handle job data correctly', () => {
    const worker = new RepomixWorker();
    const sourceDir = '/home/user/code/myproject';
    const relativePath = 'myproject';

    const job = worker.createRepomixJob(sourceDir, relativePath);

    assert.strictEqual(job.status, 'queued');
    assert.ok(job.data);
    assert.strictEqual(job.data.sourceDir, sourceDir);
    assert.strictEqual(job.data.relativePath, relativePath);
    assert.strictEqual(job.data.type, 'repomix');
  });

  test('should queue multiple jobs', () => {
    const worker = new RepomixWorker();

    worker.createRepomixJob('/dir1', 'dir1');
    worker.createRepomixJob('/dir2', 'dir2');
    worker.createRepomixJob('/dir3', 'dir3');

    const allJobs = worker.getAllJobs();
    assert.strictEqual(allJobs.length, 3);
  });

  test('should inherit from SidequestServer', () => {
    const worker = new RepomixWorker();

    // Should have SidequestServer methods
    assert.ok(typeof worker.createJob === 'function');
    assert.ok(typeof worker.getJob === 'function');
    assert.ok(typeof worker.getAllJobs === 'function');
    assert.ok(typeof worker.getStats === 'function');
  });

  test('should emit job events', (t, done) => {
    const worker = new RepomixWorker();
    let createdFired = false;

    worker.on('job:created', (job) => {
      assert.ok(job.id);
      assert.strictEqual(job.data.type, 'repomix');
      createdFired = true;
      done();
    });

    worker.createRepomixJob('/test/dir', 'test-dir');
  });
});
</file>

<file path="schema-mcp-tools.test.js">
import { test, describe } from 'node:test';
import assert from 'node:assert';
import { SchemaMCPTools } from '../sidequest/doc-enhancement/schema-mcp-tools.js';

describe('SchemaMCPTools', () => {
  test('should initialize with default options', () => {
    const tools = new SchemaMCPTools();
    assert.strictEqual(tools.useRealMCP, false);
  });

  test('should detect HowTo schema for test documentation', async () => {
    const tools = new SchemaMCPTools();
    const readmePath = '/projects/myapp/tests/README.md';
    const content = '# Testing Guide\n\nHow to test this application.';
    const context = {};

    const schemaType = await tools.getSchemaType(readmePath, content, context);

    assert.strictEqual(schemaType, 'HowTo');
  });

  test('should detect APIReference schema for API docs', async () => {
    const tools = new SchemaMCPTools();
    const readmePath = '/projects/myapp/api/README.md';
    const content = '# API Reference\n\nEndpoints and usage.';
    const context = {};

    const schemaType = await tools.getSchemaType(readmePath, content, context);

    assert.strictEqual(schemaType, 'APIReference');
  });

  test('should detect SoftwareApplication for projects with package.json', async () => {
    const tools = new SchemaMCPTools();
    const readmePath = '/projects/myapp/README.md';
    const content = '# My App\n\nAn amazing application.';
    const context = { hasPackageJson: true };

    const schemaType = await tools.getSchemaType(readmePath, content, context);

    assert.strictEqual(schemaType, 'SoftwareApplication');
  });

  test('should detect SoftwareSourceCode for repos with git remote', async () => {
    const tools = new SchemaMCPTools();
    const readmePath = '/projects/myapp/README.md';
    const content = '# My Project';
    const context = { gitRemote: 'https://github.com/user/repo.git' };

    const schemaType = await tools.getSchemaType(readmePath, content, context);

    assert.strictEqual(schemaType, 'SoftwareSourceCode');
  });

  test('should detect HowTo for tutorial content', async () => {
    const tools = new SchemaMCPTools();
    const readmePath = '/projects/docs/README.md';
    const content = '# Getting Started Tutorial\n\nStep by step guide.';
    const context = {};

    const schemaType = await tools.getSchemaType(readmePath, content, context);

    assert.strictEqual(schemaType, 'HowTo');
  });

  test('should default to TechArticle for general docs', async () => {
    const tools = new SchemaMCPTools();
    const readmePath = '/projects/docs/README.md';
    const content = '# Documentation\n\nGeneral information.';
    const context = {};

    const schemaType = await tools.getSchemaType(readmePath, content, context);

    assert.strictEqual(schemaType, 'TechArticle');
  });

  test('should generate schema with extracted title', async () => {
    const tools = new SchemaMCPTools();
    const readmePath = '/projects/myapp/README.md';
    const content = '# My Awesome App\n\nThis is a great application.';
    const context = { languages: ['JavaScript'] };

    const schema = await tools.generateSchema(readmePath, content, context, 'SoftwareApplication');

    assert.strictEqual(schema['@context'], 'https://schema.org');
    assert.strictEqual(schema['@type'], 'SoftwareApplication');
    assert.strictEqual(schema.name, 'My Awesome App');
    assert.ok(schema.description);
  });

  test('should extract description from content', () => {
    const tools = new SchemaMCPTools();
    const content = '# Title\n\nThis is the description paragraph.\n\nMore content.';

    const description = tools.extractDescription(content);

    assert.strictEqual(description, 'This is the description paragraph.');
  });

  test('should limit description length', () => {
    const tools = new SchemaMCPTools();
    const longText = 'a'.repeat(250);
    const content = `# Title\n\n${longText}`;

    const description = tools.extractDescription(content);

    assert.ok(description.length <= 200);
    assert.ok(description.endsWith('...'));
  });

  test('should add programming languages to schema', async () => {
    const tools = new SchemaMCPTools();
    const readmePath = '/projects/myapp/README.md';
    const content = '# My App';
    const context = {
      languages: ['JavaScript', 'TypeScript'],
      gitRemote: 'https://github.com/user/repo.git'
    };

    const schema = await tools.generateSchema(readmePath, content, context, 'SoftwareSourceCode');

    assert.ok(Array.isArray(schema.programmingLanguage));
    assert.strictEqual(schema.programmingLanguage.length, 2);
    assert.strictEqual(schema.programmingLanguage[0]['@type'], 'ComputerLanguage');
    assert.strictEqual(schema.programmingLanguage[0].name, 'JavaScript');
  });

  test('should add code repository to schema', async () => {
    const tools = new SchemaMCPTools();
    const readmePath = '/projects/myapp/README.md';
    const content = '# My App';
    const context = { gitRemote: 'https://github.com/user/repo.git' };

    const schema = await tools.generateSchema(readmePath, content, context, 'SoftwareSourceCode');

    assert.strictEqual(schema.codeRepository, 'https://github.com/user/repo.git');
  });

  test('should validate valid schema', async () => {
    const tools = new SchemaMCPTools();
    const schema = {
      '@context': 'https://schema.org',
      '@type': 'TechArticle',
      name: 'Test Article',
      description: 'Test description',
    };

    const validation = await tools.validateSchema(schema);

    assert.strictEqual(validation.valid, true);
    assert.strictEqual(validation.errors.length, 0);
  });

  test('should detect missing @context', async () => {
    const tools = new SchemaMCPTools();
    const schema = {
      '@type': 'TechArticle',
      name: 'Test',
    };

    const validation = await tools.validateSchema(schema);

    assert.strictEqual(validation.valid, false);
    assert.ok(validation.errors.some(e => e.includes('@context')));
  });

  test('should detect missing @type', async () => {
    const tools = new SchemaMCPTools();
    const schema = {
      '@context': 'https://schema.org',
      name: 'Test',
    };

    const validation = await tools.validateSchema(schema);

    assert.strictEqual(validation.valid, false);
    assert.ok(validation.errors.some(e => e.includes('@type')));
  });

  test('should warn about missing recommended properties', async () => {
    const tools = new SchemaMCPTools();
    const schema = {
      '@context': 'https://schema.org',
      '@type': 'TechArticle',
    };

    const validation = await tools.validateSchema(schema);

    assert.strictEqual(validation.valid, true);
    assert.ok(validation.warnings.length > 0);
    assert.ok(validation.warnings.some(w => w.includes('name')));
  });

  test('should analyze schema impact', async () => {
    const tools = new SchemaMCPTools();
    const originalContent = '# Test\n\nOriginal content';
    const enhancedContent = originalContent + '\n<script type="application/ld+json">\n{}\n</script>';
    const schema = {
      '@context': 'https://schema.org',
      '@type': 'SoftwareApplication',
      name: 'Test App',
      description: 'Test description',
      programmingLanguage: [{ '@type': 'ComputerLanguage', name: 'JavaScript' }],
    };

    const impact = await tools.analyzeSchemaImpact(originalContent, enhancedContent, schema);

    assert.ok(impact.timestamp);
    assert.strictEqual(impact.schemaType, 'SoftwareApplication');
    assert.ok(impact.metrics.contentSize.original < impact.metrics.contentSize.enhanced);
    assert.ok(impact.seoImprovements.length > 0);
    assert.ok(impact.impactScore > 0);
    assert.ok(impact.rating);
  });

  test('should calculate high impact score for well-structured schema', async () => {
    const tools = new SchemaMCPTools();
    const schema = {
      '@context': 'https://schema.org',
      '@type': 'SoftwareApplication',
      name: 'Test App',
      description: 'Test description',
      codeRepository: 'https://github.com/user/repo',
      programmingLanguage: [{ '@type': 'ComputerLanguage', name: 'JavaScript' }],
    };

    const impact = await tools.analyzeSchemaImpact('original', 'enhanced', schema);

    assert.ok(impact.impactScore >= 80);
    assert.strictEqual(impact.rating, 'Excellent');
  });

  test('should create JSON-LD script tag', () => {
    const tools = new SchemaMCPTools();
    const schema = {
      '@context': 'https://schema.org',
      '@type': 'TechArticle',
      name: 'Test',
    };

    const script = tools.createJSONLDScript(schema);

    assert.ok(script.includes('<script type="application/ld+json">'));
    assert.ok(script.includes('"@context": "https://schema.org"'));
    assert.ok(script.includes('</script>'));
  });

  test('should inject schema into content', () => {
    const tools = new SchemaMCPTools();
    const content = '# My Title\n\nSome content here.';
    const schema = {
      '@context': 'https://schema.org',
      '@type': 'TechArticle',
      name: 'Test',
    };

    const enhanced = tools.injectSchema(content, schema);

    assert.ok(enhanced.includes('# My Title'));
    assert.ok(enhanced.includes('<script type="application/ld+json">'));
    assert.ok(enhanced.includes('"@type": "TechArticle"'));

    // Schema should be after the title
    const titleIndex = enhanced.indexOf('# My Title');
    const schemaIndex = enhanced.indexOf('<script type="application/ld+json">');
    assert.ok(schemaIndex > titleIndex);
  });

  test('should handle content without heading', () => {
    const tools = new SchemaMCPTools();
    const content = 'Just some content without a heading.';
    const schema = {
      '@context': 'https://schema.org',
      '@type': 'TechArticle',
      name: 'Test',
    };

    const enhanced = tools.injectSchema(content, schema);

    assert.ok(enhanced.includes('<script type="application/ld+json">'));
    assert.ok(enhanced.includes('Just some content'));
  });

  test('should provide correct rating for different scores', () => {
    const tools = new SchemaMCPTools();

    assert.strictEqual(tools.getRating(90), 'Excellent');
    assert.strictEqual(tools.getRating(70), 'Good');
    assert.strictEqual(tools.getRating(50), 'Fair');
    assert.strictEqual(tools.getRating(30), 'Needs Improvement');
  });
});
</file>

<file path="sidequest-server.test.js">
import { test, describe } from 'node:test';
import assert from 'node:assert';
import { SidequestServer } from '../sidequest/server.js';
import fs from 'fs/promises';
import path from 'path';
import os from 'os';

// Mock SidequestServer for testing
class TestSidequestServer extends SidequestServer {
  async runJobHandler(job) {
    // Simulate job execution
    if (job.data.shouldFail) {
      throw new Error('Simulated job failure');
    }
    return { success: true, data: job.data };
  }
}

describe('SidequestServer', () => {
  test('should initialize with default options', () => {
    const server = new TestSidequestServer();
    assert.strictEqual(server.maxConcurrent, 5);
    assert.strictEqual(server.activeJobs, 0);
    assert.ok(server.jobs instanceof Map);
    assert.ok(Array.isArray(server.queue));
  });

  test('should initialize with custom options', () => {
    const server = new TestSidequestServer({
      maxConcurrent: 10,
      logDir: '/custom/logs',
    });

    assert.strictEqual(server.maxConcurrent, 10);
    assert.strictEqual(server.logDir, '/custom/logs');
  });

  test('should create a job', () => {
    const server = new TestSidequestServer();
    const job = server.createJob('test-job-1', { foo: 'bar' });

    assert.strictEqual(job.id, 'test-job-1');
    assert.strictEqual(job.status, 'queued');
    assert.deepStrictEqual(job.data, { foo: 'bar' });
    assert.ok(job.createdAt instanceof Date);
    assert.strictEqual(job.startedAt, null);
    assert.strictEqual(job.completedAt, null);
  });

  test('should add job to queue', () => {
    const server = new TestSidequestServer();
    server.createJob('test-job-1', { foo: 'bar' });

    assert.strictEqual(server.queue.length, 1);
    assert.strictEqual(server.queue[0], 'test-job-1');
  });

  test('should store job in jobs Map', () => {
    const server = new TestSidequestServer();
    server.createJob('test-job-1', { foo: 'bar' });

    assert.ok(server.jobs.has('test-job-1'));
    const job = server.jobs.get('test-job-1');
    assert.strictEqual(job.id, 'test-job-1');
  });

  test('should execute job successfully', async () => {
    const tempLogDir = path.join(os.tmpdir(), 'test-logs-' + Date.now());
    await fs.mkdir(tempLogDir, { recursive: true });

    try {
      const server = new TestSidequestServer({
        logDir: tempLogDir,
      });

      const job = server.createJob('test-job-1', { foo: 'bar' });

      // Wait for job to complete
      await new Promise((resolve) => {
        server.on('job:completed', (completedJob) => {
          if (completedJob.id === 'test-job-1') {
            resolve();
          }
        });
      });

      const completedJob = server.getJob('test-job-1');
      assert.strictEqual(completedJob.status, 'completed');
      assert.ok(completedJob.startedAt instanceof Date);
      assert.ok(completedJob.completedAt instanceof Date);
      assert.ok(completedJob.result);
      assert.strictEqual(completedJob.result.success, true);
    } finally {
      await fs.rm(tempLogDir, { recursive: true, force: true });
    }
  });

  test('should handle job failure', async () => {
    const tempLogDir = path.join(os.tmpdir(), 'test-logs-fail-' + Date.now());
    await fs.mkdir(tempLogDir, { recursive: true });

    try {
      const server = new TestSidequestServer({
        logDir: tempLogDir,
      });

      server.createJob('test-job-fail', { shouldFail: true });

      // Wait for job to fail
      await new Promise((resolve) => {
        server.on('job:failed', (failedJob) => {
          if (failedJob.id === 'test-job-fail') {
            resolve();
          }
        });
      });

      const failedJob = server.getJob('test-job-fail');
      assert.strictEqual(failedJob.status, 'failed');
      assert.ok(failedJob.error);
      assert.ok(failedJob.error.includes('Simulated job failure'));
    } finally {
      await fs.rm(tempLogDir, { recursive: true, force: true });
    }
  });

  test('should respect maxConcurrent limit', async () => {
    const server = new TestSidequestServer({
      maxConcurrent: 2,
    });

    // Create 5 jobs
    for (let i = 0; i < 5; i++) {
      server.createJob(`job-${i}`, { id: i });
    }

    // Check that only 2 are active at most
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Active jobs should not exceed maxConcurrent
    assert.ok(server.activeJobs <= 2);
  });

  test('should emit job events', (t, done) => {
    const server = new TestSidequestServer();
    let eventsFired = [];

    server.on('job:created', () => eventsFired.push('created'));
    server.on('job:started', () => eventsFired.push('started'));
    server.on('job:completed', () => {
      eventsFired.push('completed');
      assert.ok(eventsFired.includes('created'));
      assert.ok(eventsFired.includes('started'));
      assert.ok(eventsFired.includes('completed'));
      done();
    });

    server.createJob('event-test', { foo: 'bar' });
  });

  test('should get job by id', () => {
    const server = new TestSidequestServer();
    server.createJob('test-job-1', { foo: 'bar' });

    const job = server.getJob('test-job-1');
    assert.ok(job);
    assert.strictEqual(job.id, 'test-job-1');
  });

  test('should get all jobs', () => {
    const server = new TestSidequestServer();
    server.createJob('job-1', { id: 1 });
    server.createJob('job-2', { id: 2 });

    const allJobs = server.getAllJobs();
    assert.strictEqual(allJobs.length, 2);
  });

  test('should get stats', async () => {
    const server = new TestSidequestServer();
    server.createJob('job-1', { id: 1 });

    // Wait for job to complete
    await new Promise((resolve) => {
      server.on('job:completed', () => resolve());
    });

    const stats = server.getStats();
    assert.ok(stats.total >= 1);
    assert.ok(stats.completed >= 1);
  });
});
</file>

<file path="test-directory-scanner.js">
import { DirectoryScanner } from '../sidequest/directory-scanner.js';
import path from 'path';

/**
 * Test script for directory scanner with output generation
 * Usage: node test-directory-scanner.js [directory-path]
 */

async function testDirectoryScanner() {
  console.log('=== Directory Scanner Test ===\n');

  // Get target directory from command line or use current directory
  const targetDir = process.argv[2] || process.cwd();
  const absolutePath = path.resolve(targetDir);

  console.log(`Target directory: ${absolutePath}\n`);

  // Create scanner
  const scanner = new DirectoryScanner({
    baseDir: absolutePath,
    outputDir: './directory-scan-reports',
    excludeDirs: [
      'node_modules',
      '.git',
      'dist',
      'build',
      'coverage',
      '.next',
      '__pycache__',
      '.venv',
      'venv',
    ],
    maxDepth: 5, // Limit depth for testing
  });

  try {
    const startTime = Date.now();

    // Scan directories
    console.log('üìÇ Scanning directories...');
    const directories = await scanner.scanDirectories();
    const scanDuration = Date.now() - startTime;

    console.log(`‚úì Found ${directories.length} directories in ${scanDuration}ms\n`);

    if (directories.length === 0) {
      console.log('No directories found to process');
      return;
    }

    // Generate statistics
    console.log('üìä Generating statistics...');
    const stats = scanner.generateScanStats(directories);

    console.log('\nScan Statistics:');
    console.log('================');
    console.log(`Total directories: ${stats.total}`);
    console.log(`\nDirectories by depth:`);
    for (const [depth, count] of Object.entries(stats.byDepth)) {
      console.log(`  Depth ${depth}: ${count} directories`);
    }

    console.log(`\nTop 10 directory names:`);
    for (const { name, count } of stats.topDirectoryNames) {
      console.log(`  ${name}: ${count} occurrences`);
    }

    // Generate and save scan results
    console.log('\nüíæ Saving scan results...');
    const results = await scanner.generateAndSaveScanResults(directories);

    console.log('\n‚úì Scan results saved:');
    console.log(`  Report: ${results.reportPath}`);
    console.log(`  Tree: ${results.treePath}`);
    console.log(`  Summary: ${results.summaryPath}`);

    // Show tree preview (first 20 lines)
    console.log('\nüìÅ Directory Tree Preview (first 20 lines):');
    console.log('===========================================');
    const tree = scanner.generateDirectoryTree(directories);
    const treeLines = tree.split('\n').slice(0, 20);
    console.log(treeLines.join('\n'));
    if (tree.split('\n').length > 20) {
      console.log(`... (${tree.split('\n').length - 20} more lines)`);
    }

    console.log('\n‚úì Test completed successfully!');
    console.log(`\nTotal duration: ${Date.now() - startTime}ms`);

  } catch (error) {
    console.error('Error during directory scan:', error);
    process.exit(1);
  }
}

// Run the test
testDirectoryScanner().catch((error) => {
  console.error('Fatal error:', error);
  process.exit(1);
});
</file>

<file path="test-sentry-connection.js">
#!/usr/bin/env node
/**
 * Test Sentry Connection
 * Sends a test message to verify Sentry is configured correctly
 */

import Sentry from '@sentry/node';
import dotenv from 'dotenv';

// Load environment variables
dotenv.config();

async function testSentryConnection() {
  console.log('üß™ Testing Sentry Connection...\n');

  // Check if DSN is configured
  if (!process.env.SENTRY_DSN || process.env.SENTRY_DSN === 'your_sentry_dsn_here') {
    console.error('‚ùå SENTRY_DSN not configured in .env file');
    console.error('   Please run: npm run setup:sentry');
    process.exit(1);
  }

  console.log('‚úÖ SENTRY_DSN found in environment');
  console.log(`   DSN: ${process.env.SENTRY_DSN.substring(0, 50)}...\n`);

  // Initialize Sentry
  Sentry.init({
    dsn: process.env.SENTRY_DSN,
    environment: 'test',
    tracesSampleRate: 1.0,
  });

  console.log('‚úÖ Sentry initialized\n');

  // Send test message
  console.log('üì§ Sending test message to Sentry...');

  const eventId = Sentry.captureMessage(
    'Sentry connection test successful! üéâ',
    'info'
  );

  console.log(`‚úÖ Test message sent!`);
  console.log(`   Event ID: ${eventId}\n`);

  // Send test error
  console.log('üì§ Sending test error to Sentry...');

  const errorId = Sentry.captureException(
    new Error('Test error - This is a test error to verify Sentry error tracking')
  );

  console.log(`‚úÖ Test error sent!`);
  console.log(`   Error ID: ${errorId}\n`);

  // Flush events to Sentry
  console.log('‚è≥ Flushing events to Sentry...');
  await Sentry.flush(2000);

  console.log('\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
  console.log('‚ïë              Sentry Connection Test Complete! ‚úÖ              ‚ïë');
  console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n');

  console.log('üìä Check your Sentry dashboard to see the test messages:');
  console.log('   https://sentry.io/\n');

  console.log('You should see:');
  console.log('   1. Info message: "Sentry connection test successful! üéâ"');
  console.log('   2. Error: "Test error - This is a test error..."\n');

  console.log('Next steps:');
  console.log('   ‚Ä¢ Set up alerts in Sentry dashboard');
  console.log('   ‚Ä¢ Configure Slack/email notifications');
  console.log('   ‚Ä¢ Run your jobs - errors will be automatically tracked!\n');
}

testSentryConnection().catch((error) => {
  console.error('\n‚ùå Fatal error during test:', error);
  process.exit(1);
});
</file>

<file path="test-single-enhancement.js">
import { SchemaEnhancementWorker } from '../sidequest/doc-enhancement/schema-enhancement-worker.js';
import { READMEScanner } from '../sidequest/doc-enhancement/readme-scanner.js';
import path from 'path';

/**
 * Test script to enhance a single README file
 * Usage: node test-single-enhancement.js [readme-path] [--dry-run]
 */

async function testSingleEnhancement() {
  console.log('=== Single README Enhancement Test ===\n');

  // Parse arguments
  const args = process.argv.slice(2);
  let readmePath = args[0] || 'README.md';
  const dryRun = args.includes('--dry-run');

  // Resolve to absolute path
  readmePath = path.resolve(readmePath);
  console.log(`Target README: ${readmePath}`);
  console.log(`Dry run: ${dryRun}\n`);

  // Create worker
  const worker = new SchemaEnhancementWorker({
    maxConcurrent: 1,
    outputBaseDir: './document-enhancement-impact-measurement',
    logDir: './logs',
    sentryDsn: process.env.SENTRY_DSN,
    dryRun,
  });

  // Create scanner for context gathering
  const scanner = new READMEScanner({
    baseDir: path.dirname(readmePath),
  });

  // Setup event listeners
  worker.on('job:created', (job) => {
    console.log(`‚úì Job created: ${job.id}`);
  });

  worker.on('job:started', (job) => {
    console.log(`‚ñ∂ Job started: ${job.id}`);
    console.log(`  README: ${job.data.readmePath}`);
  });

  worker.on('job:completed', (job) => {
    const duration = job.completedAt - job.startedAt;
    console.log(`\n‚úì Job completed successfully!`);
    console.log(`  Duration: ${Math.round(duration / 1000)}s`);

    if (job.result.status === 'enhanced') {
      console.log(`  Schema type: ${job.result.schemaType}`);
      console.log(`  Impact score: ${job.result.impact.impactScore}/100 (${job.result.impact.rating})`);
      console.log(`  SEO improvements: ${job.result.impact.seoImprovements.length}`);
      console.log(`  Rich results: ${job.result.impact.richResultsEligibility.length}`);
      console.log(`\n  Schema generated:`);
      console.log(JSON.stringify(job.result.schema, null, 2));
      console.log(`\n  Impact report saved to: document-enhancement-impact-measurement/impact-reports/`);
      console.log(`  Enhanced copy saved to: document-enhancement-impact-measurement/enhanced-readmes/`);
    } else {
      console.log(`  Status: ${job.result.status}`);
      console.log(`  Reason: ${job.result.reason}`);
    }

    console.log(`\n  Log file: ./logs/${job.id}.json`);
    process.exit(0);
  });

  worker.on('job:failed', (job) => {
    console.error(`\n‚úó Job failed!`);
    console.error(`  Error: ${job.error}`);
    console.error(`  Log file: ./logs/${job.id}.error.json`);
    process.exit(1);
  });

  try {
    // Check if README exists
    const fs = await import('fs/promises');
    await fs.access(readmePath);

    // Gather context
    console.log('üìÇ Gathering context...');
    const dirPath = path.dirname(readmePath);
    const context = await scanner.gatherContext(dirPath);
    console.log(`  Languages: ${Array.from(context.languages).join(', ') || 'None detected'}`);
    console.log(`  Git remote: ${context.gitRemote || 'None'}`);
    console.log(`  Project type: ${context.projectType}\n`);

    // Create README object
    const readme = {
      fullPath: readmePath,
      relativePath: path.basename(readmePath),
      fileName: path.basename(readmePath),
      dirPath,
      depth: 0,
    };

    // Create and run the job
    console.log('üöÄ Creating enhancement job...\n');
    const job = worker.createEnhancementJob(readme, context);

    // Wait for job to complete
    await new Promise((resolve) => {
      const checkInterval = setInterval(() => {
        if (job.status === 'completed' || job.status === 'failed') {
          clearInterval(checkInterval);
          resolve();
        }
      }, 100);
    });

  } catch (error) {
    console.error('Error:', error.message);
    process.exit(1);
  }
}

// Run the test
testSingleEnhancement().catch((error) => {
  console.error('Fatal error:', error);
  process.exit(1);
});
</file>

<file path="test-single-job.js">
import { RepomixWorker } from '../sidequest/repomix-worker.js';
import { DirectoryScanner } from '../sidequest/directory-scanner.js';
import path from 'path';
import os from 'os';

/**
 * Test script to run a single repomix job
 * Usage: node test-single-job.js [directory-path]
 */

async function testSingleJob() {
  console.log('=== Single Job Test ===\n');

  // Get target directory from command line or use current directory
  const targetDir = process.argv[2] || process.cwd();
  const absolutePath = path.resolve(targetDir);

  console.log(`Target directory: ${absolutePath}`);

  // Calculate relative path from ~/code
  const codeBase = path.join(os.homedir(), 'code');
  let relativePath;

  if (absolutePath.startsWith(codeBase)) {
    relativePath = path.relative(codeBase, absolutePath);
  } else {
    // If not under ~/code, use the directory name
    relativePath = path.basename(absolutePath);
  }

  console.log(`Relative path: ${relativePath}`);
  console.log(`Output will be saved to: ./condense/${relativePath}/repomix-output.txt\n`);

  // Create worker
  const worker = new RepomixWorker({
    maxConcurrent: 1,
    outputBaseDir: './condense',
    codeBaseDir: codeBase,
    logDir: './logs',
    sentryDsn: process.env.SENTRY_DSN,
  });

  // Setup event listeners
  worker.on('job:created', (job) => {
    console.log(`‚úì Job created: ${job.id}`);
  });

  worker.on('job:started', (job) => {
    console.log(`‚ñ∂ Job started: ${job.id}`);
    console.log(`  Source: ${job.data.sourceDir}`);
    console.log(`  Relative path: ${job.data.relativePath}`);
  });

  worker.on('job:completed', (job) => {
    const duration = job.completedAt - job.startedAt;
    console.log(`\n‚úì Job completed successfully!`);
    console.log(`  Duration: ${Math.round(duration / 1000)}s`);
    console.log(`  Output file: ${job.result.outputFile}`);
    console.log(`  File size: ${(job.result.size / 1024).toFixed(2)} KB`);
    console.log(`  Log file: ./logs/${job.id}.json`);
    process.exit(0);
  });

  worker.on('job:failed', (job) => {
    console.error(`\n‚úó Job failed!`);
    console.error(`  Error: ${job.error}`);
    console.error(`  Log file: ./logs/${job.id}.error.json`);
    process.exit(1);
  });

  // Create and run the job
  console.log('Creating job...\n');
  const job = worker.createRepomixJob(absolutePath, relativePath);

  // Wait for job to complete
  await new Promise((resolve) => {
    const checkInterval = setInterval(() => {
      if (job.status === 'completed' || job.status === 'failed') {
        clearInterval(checkInterval);
        resolve();
      }
    }, 100);
  });
}

// Run the test
testSingleJob().catch((error) => {
  console.error('Fatal error:', error);
  process.exit(1);
});
</file>

</files>
